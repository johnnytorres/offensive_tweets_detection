{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(dataset, labels, header):\n",
    "    pred_labels=[l+'_pred' for l in labels]\n",
    "    y_true = dataset[labels]\n",
    "    y_pred = dataset[pred_labels]\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred)\n",
    "    metrics = [list(m) for m in metrics]\n",
    "\n",
    "    avg = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    avg = np.array(avg)\n",
    "    avg[3] = np.sum(metrics[3])\n",
    "\n",
    "    m = np.array(metrics)\n",
    "    m2 = np.append(m.T,  np.array(avg).reshape(1,4), axis=0)\n",
    "    m2=m2[:,:3]\n",
    "    stat=m2.flatten()\n",
    "    stat=stat.reshape(-1,1).T * 100\n",
    "    lstat=stat.flatten().tolist()\n",
    "    header.extend(lstat)\n",
    "    return header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39719 entries, 0 to 39718\n",
      "Data columns (total 15 columns):\n",
      "subtask_a         39719 non-null object\n",
      "subtask_a_pred    39719 non-null object\n",
      "run_id            39719 non-null object\n",
      "timestamp         39719 non-null int64\n",
      "model             39719 non-null object\n",
      "set               39719 non-null object\n",
      "kfold             39719 non-null int64\n",
      "id                39719 non-null object\n",
      "Unnamed: 8        39719 non-null object\n",
      "Unnamed: 9        39719 non-null object\n",
      "Unnamed: 10       39719 non-null object\n",
      "Unnamed: 11       39719 non-null object\n",
      "Unnamed: 12       39719 non-null object\n",
      "Unnamed: 13       39719 non-null object\n",
      "Unnamed: 14       39719 non-null object\n",
      "dtypes: int64(2), object(13)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "path='/Users/johnny/data/toxicity/offens_eval/results/predictions_embeddings.csv'\n",
    "ds = pd.read_csv(path,keep_default_na=False)\n",
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>subtask_a_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>run_id</th>\n",
       "      <th>set</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">66adfa44-e68d-4fbe-a2b3-926124913125</th>\n",
       "      <th>cv</th>\n",
       "      <td>10592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn-glove</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">e5bf8023-0472-4399-990b-a234050bebb5</th>\n",
       "      <th>cv</th>\n",
       "      <td>10591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn-w2v</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ec81747c-ce8e-4a0e-8a5a-60c4f5b552d0</th>\n",
       "      <th>cv</th>\n",
       "      <td>10592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     subtask_a_pred\n",
       "model     run_id                               set                 \n",
       "cnn       66adfa44-e68d-4fbe-a2b3-926124913125 cv             10592\n",
       "                                               test            2648\n",
       "cnn-glove e5bf8023-0472-4399-990b-a234050bebb5 cv             10591\n",
       "                                               test            2648\n",
       "cnn-w2v   ec81747c-ce8e-4a0e-8a5a-60c4f5b552d0 cv             10592\n",
       "                                               test            2648"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.groupby(['model','run_id','set']).agg({'subtask_a_pred': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.81      0.84      0.83      1759\n",
      "         OFF       0.66      0.60      0.63       889\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2648\n",
      "   macro avg       0.73      0.72      0.73      2648\n",
      "weighted avg       0.76      0.76      0.76      2648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = ds[(ds.model=='cnn-glove') & (ds.set=='test')]\n",
    "print(classification_report(results.subtask_a, results.subtask_a_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking = []\n",
    "\n",
    "labels =['subtask_a']\n",
    "\n",
    "results = ds[(ds.model=='cnn') & (ds.set=='test')]\n",
    "m=calc_metrics(results, labels, ['Random'])\n",
    "benchmarking.append(m)\n",
    "\n",
    "results = ds[(ds.model=='cnn-w2v') & (ds.set=='test')]\n",
    "m=calc_metrics(results, labels, ['Word2Vec'])\n",
    "benchmarking.append(m)\n",
    "\n",
    "results = ds[(ds.model=='cnn-glove') & (ds.set=='test')]\n",
    "m=calc_metrics(results, labels, ['Glove'])\n",
    "benchmarking.append(m)\n",
    "\n",
    "\n",
    "# results = ds[(ds.model=='lstm') & (ds.set=='test')]\n",
    "# m=calc_metrics(results, labels, ['LSTM'])\n",
    "# benchmarking.append(m)\n",
    "\n",
    "# results = ds[(ds.model=='bilstm') & (ds.set=='test')]\n",
    "# m=calc_metrics(results, labels, ['BI-LSTM'])\n",
    "# benchmarking.append(m)\n",
    "\n",
    "# results = ds[(ds.model=='fasttext') & (ds.set=='test')]\n",
    "# m=calc_metrics(results, labels, ['FastText'])\n",
    "# benchmarking.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>NOT-P</th>\n",
       "      <th>NOT-R</th>\n",
       "      <th>NOT-F1</th>\n",
       "      <th>OFF-P</th>\n",
       "      <th>OFF-R</th>\n",
       "      <th>OFF-F1</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random</td>\n",
       "      <td>78.433420</td>\n",
       "      <td>85.389426</td>\n",
       "      <td>81.763745</td>\n",
       "      <td>64.938608</td>\n",
       "      <td>53.543307</td>\n",
       "      <td>58.692972</td>\n",
       "      <td>71.686014</td>\n",
       "      <td>69.466366</td>\n",
       "      <td>70.228358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>79.633740</td>\n",
       "      <td>81.580443</td>\n",
       "      <td>80.595338</td>\n",
       "      <td>61.702128</td>\n",
       "      <td>58.717660</td>\n",
       "      <td>60.172911</td>\n",
       "      <td>70.667934</td>\n",
       "      <td>70.149052</td>\n",
       "      <td>70.384125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glove</td>\n",
       "      <td>80.717002</td>\n",
       "      <td>84.479818</td>\n",
       "      <td>82.555556</td>\n",
       "      <td>66.171004</td>\n",
       "      <td>60.067492</td>\n",
       "      <td>62.971698</td>\n",
       "      <td>73.444003</td>\n",
       "      <td>72.273655</td>\n",
       "      <td>72.763627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model      NOT-P     NOT-R      NOT-F1      OFF-P      OFF-R     OFF-F1  \\\n",
       "0    Random  78.433420  85.389426  81.763745  64.938608  53.543307  58.692972   \n",
       "1  Word2Vec  79.633740  81.580443  80.595338  61.702128  58.717660  60.172911   \n",
       "2     Glove  80.717002  84.479818  82.555556  66.171004  60.067492  62.971698   \n",
       "\n",
       "           P          R         F1  \n",
       "0  71.686014  69.466366  70.228358  \n",
       "1  70.667934  70.149052  70.384125  \n",
       "2  73.444003  72.273655  72.763627  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = ['model', 'NOT-P', 'NOT-R ', 'NOT-F1','OFF-P', 'OFF-R', 'OFF-F1','P', 'R', 'F1']\n",
    "dsstat=pd.DataFrame(benchmarking, columns=c)\n",
    "path = '~/data/toxicity/offens_eval/results/models_embeddings.csv'\n",
    "dsstat.to_csv(path, index=False)\n",
    "dsstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66200 entries, 0 to 66199\n",
      "Data columns (total 8 columns):\n",
      "subtask_a         66200 non-null object\n",
      "subtask_a_pred    66200 non-null object\n",
      "run_id            66200 non-null object\n",
      "timestamp         66200 non-null float64\n",
      "model             66200 non-null object\n",
      "set               66200 non-null object\n",
      "kfold             66200 non-null int64\n",
      "id                66200 non-null int64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "path='/Users/johnny/data/toxicity/offens_eval/results/predictions_taska.csv'\n",
    "ds = pd.read_csv(path,keep_default_na=False)\n",
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['NOT', 'OFF'], dtype=object), array(['NOT', 'OFF'], dtype=object))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.subtask_a.unique(),ds.subtask_a_pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>subtask_a_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>run_id</th>\n",
       "      <th>set</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bilstm</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">597e34df-b3d9-4ac7-bd68-3c8dec7d59a4</th>\n",
       "      <th>cv</th>\n",
       "      <td>10592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">f97a003e-abfd-488d-85bb-84c769b95a3e</th>\n",
       "      <th>cv</th>\n",
       "      <td>10592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fasttext</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ee861b93-3059-478f-8b83-03cabe096680</th>\n",
       "      <th>cv</th>\n",
       "      <td>10592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">lr</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">407c2a6d-e60a-481e-84e7-6b62ffa97f07</th>\n",
       "      <th>cv</th>\n",
       "      <td>10592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">lstm</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0dbcf6a9-d4bf-47a9-898e-7ac60b36c139</th>\n",
       "      <th>cv</th>\n",
       "      <td>10592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    subtask_a_pred\n",
       "model    run_id                               set                 \n",
       "bilstm   597e34df-b3d9-4ac7-bd68-3c8dec7d59a4 cv             10592\n",
       "                                              test            2648\n",
       "cnn      f97a003e-abfd-488d-85bb-84c769b95a3e cv             10592\n",
       "                                              test            2648\n",
       "fasttext ee861b93-3059-478f-8b83-03cabe096680 cv             10592\n",
       "                                              test            2648\n",
       "lr       407c2a6d-e60a-481e-84e7-6b62ffa97f07 cv             10592\n",
       "                                              test            2648\n",
       "lstm     0dbcf6a9-d4bf-47a9-898e-7ac60b36c139 cv             10592\n",
       "                                              test            2648"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.groupby(['model','run_id','set']).agg({'subtask_a_pred': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.81      0.81      0.81      1759\n",
      "         OFF       0.62      0.63      0.63       889\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      2648\n",
      "   macro avg       0.72      0.72      0.72      2648\n",
      "weighted avg       0.75      0.75      0.75      2648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = ds[(ds.model=='cnn') & (ds.set=='test')]\n",
    "print(classification_report(results.subtask_a, results.subtask_a_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarking = []\n",
    "\n",
    "labels =['subtask_a']\n",
    "\n",
    "results = ds[(ds.model=='lr') & (ds.set=='test')]\n",
    "m=calc_metrics(results, labels, ['LR'])\n",
    "benchmarking.append(m)\n",
    "\n",
    "results = ds[(ds.model=='cnn') & (ds.set=='test')]\n",
    "m=calc_metrics(results, labels, ['CNN'])\n",
    "benchmarking.append(m)\n",
    "\n",
    "results = ds[(ds.model=='lstm') & (ds.set=='test')]\n",
    "m=calc_metrics(results, labels, ['LSTM'])\n",
    "benchmarking.append(m)\n",
    "\n",
    "results = ds[(ds.model=='bilstm') & (ds.set=='test')]\n",
    "m=calc_metrics(results, labels, ['BI-LSTM'])\n",
    "benchmarking.append(m)\n",
    "\n",
    "results = ds[(ds.model=='fasttext') & (ds.set=='test')]\n",
    "m=calc_metrics(results, labels, ['FastText'])\n",
    "benchmarking.append(m)\n",
    "\n",
    "\n",
    "#benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>NOT-P</th>\n",
       "      <th>NOT-R</th>\n",
       "      <th>NOT-F1</th>\n",
       "      <th>OFF-P</th>\n",
       "      <th>OFF-R</th>\n",
       "      <th>OFF-F1</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>81.801471</td>\n",
       "      <td>75.895395</td>\n",
       "      <td>78.737835</td>\n",
       "      <td>58.267717</td>\n",
       "      <td>66.591676</td>\n",
       "      <td>62.152231</td>\n",
       "      <td>70.034594</td>\n",
       "      <td>71.243536</td>\n",
       "      <td>70.445033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>81.332567</td>\n",
       "      <td>80.500284</td>\n",
       "      <td>80.914286</td>\n",
       "      <td>62.183021</td>\n",
       "      <td>63.442070</td>\n",
       "      <td>62.806236</td>\n",
       "      <td>71.757794</td>\n",
       "      <td>71.971177</td>\n",
       "      <td>71.860261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>77.728036</td>\n",
       "      <td>78.965321</td>\n",
       "      <td>78.341794</td>\n",
       "      <td>57.026713</td>\n",
       "      <td>55.230596</td>\n",
       "      <td>56.114286</td>\n",
       "      <td>67.377374</td>\n",
       "      <td>67.097959</td>\n",
       "      <td>67.228040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BI-LSTM</td>\n",
       "      <td>80.683091</td>\n",
       "      <td>81.921546</td>\n",
       "      <td>81.297602</td>\n",
       "      <td>63.109049</td>\n",
       "      <td>61.192351</td>\n",
       "      <td>62.135922</td>\n",
       "      <td>71.896070</td>\n",
       "      <td>71.556949</td>\n",
       "      <td>71.716762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FastText</td>\n",
       "      <td>77.871148</td>\n",
       "      <td>79.022172</td>\n",
       "      <td>78.442438</td>\n",
       "      <td>57.242178</td>\n",
       "      <td>55.568054</td>\n",
       "      <td>56.392694</td>\n",
       "      <td>67.556663</td>\n",
       "      <td>67.295113</td>\n",
       "      <td>67.417566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model      NOT-P     NOT-R      NOT-F1      OFF-P      OFF-R     OFF-F1  \\\n",
       "0        LR  81.801471  75.895395  78.737835  58.267717  66.591676  62.152231   \n",
       "1       CNN  81.332567  80.500284  80.914286  62.183021  63.442070  62.806236   \n",
       "2      LSTM  77.728036  78.965321  78.341794  57.026713  55.230596  56.114286   \n",
       "3   BI-LSTM  80.683091  81.921546  81.297602  63.109049  61.192351  62.135922   \n",
       "4  FastText  77.871148  79.022172  78.442438  57.242178  55.568054  56.392694   \n",
       "\n",
       "           P          R         F1  \n",
       "0  70.034594  71.243536  70.445033  \n",
       "1  71.757794  71.971177  71.860261  \n",
       "2  67.377374  67.097959  67.228040  \n",
       "3  71.896070  71.556949  71.716762  \n",
       "4  67.556663  67.295113  67.417566  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = ['model', 'NOT-P', 'NOT-R ', 'NOT-F1','OFF-P', 'OFF-R', 'OFF-F1','P', 'R', 'F1']\n",
    "dsstat=pd.DataFrame(benchmarking, columns=c)\n",
    "path = '~/data/toxicity/offens_eval/results/models_performance.csv'\n",
    "dsstat.to_csv(path, index=False)\n",
    "dsstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
